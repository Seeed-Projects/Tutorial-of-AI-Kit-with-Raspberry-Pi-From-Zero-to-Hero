{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "sidebar_position: 2\n",
    "---\n",
    "\n",
    "> You can get this [Notebook](https://github.com/Seeed-Projects/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/blob/main/articles/Chapter_5-Custom_Model_Development_and_Deployment/Convert_Your_Model.ipynb) on GitHub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Step 1: Prepare your environment on your host computer\n",
    "\n",
    "**ðŸ“Œ Note:ï¼šThis part of code run on your linux host computer with python3.10**\n",
    "\n",
    "The Jupyter Notebook right up have a button like ![select kernel](../../pictures/Chapter5/select_kernel.png), then you choose ```Select Another Kernel```, and choose ```Python Environments```, then choose ```Creat Python Environment``` and choose ```Venv```, then choose ```python3.10```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linux PC 6.8.0-48-generic #48~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Mon Oct  7 11:24:13 UTC 2 x86_64 x86_64 x86_64 GNU/Linux\n"
     ]
    }
   ],
   "source": [
    "# Here is my hostcomputer information\n",
    "# Linux PC 6.8.0-45-generic #45~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Sep 11 15:25:05 UTC 2 x86_64 x86_64 x86_64 GNU/Linux\n",
    "\n",
    "!uname -a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.12\n"
     ]
    }
   ],
   "source": [
    "# Here is my python version\n",
    "# Python 3.10.12\n",
    "\n",
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'hailo_model_zoo' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "# Download hailo model zoo to convert onnx model\n",
    "try:\n",
    "    ! git clone https://github.com/LJ-Hao/hailo_model_zoo.git\n",
    "except Exception as e:\n",
    "    print(f'install error: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here we need [Hailo DataFlow Compiler](https://hailo.ai/products/hailo-software/hailo-ai-software-suite/#sw-dc) to convert our model \n",
    "\n",
    "### Download from official website\n",
    "\n",
    "#### 1. Register a [Hailo account](https://hailo.ai/developer-zone/request-access/) \n",
    "\n",
    "![register_hailo](../../pictures/Chapter5/register_hailo.png)\n",
    "\n",
    "#### 2. Install [Hailo DataFlow Compiler](https://hailo.ai/developer-zone/software-downloads/)\n",
    "\n",
    "![install_hailo](../../pictures/Chapter5/install_compiler.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "install successfully\n"
     ]
    }
   ],
   "source": [
    "# Install HailoDFC to compile the model\n",
    "\n",
    "try:\n",
    "    %pip install ../resource/hailo_dataflow_compiler-3.29.0-py3-none-linux_x86_64.whl -q\n",
    "    print('install successfully')\n",
    "except:\n",
    "    print('install error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m  DEPRECATION: Legacy editable install of hailo-model-zoo==2.13.0 from file:///home/jiahao/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/articles/Chapter_5-Custom_Model_Development_and_Deployment/hailo_model_zoo (setup.py develop) is deprecated. pip 25.0 will enforce this behaviour change. A possible replacement is to add a pyproject.toml or enable --use-pep517, and use setuptools >= 64. If the resulting installation is not behaving as expected, try using --config-settings editable_mode=compat. Please consult the setuptools documentation for more information. Discussion can be found at https://github.com/pypa/pip/issues/11457\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Install hailo model zoo\n",
    "\n",
    "try:\n",
    "    ! cd hailo_model_zoo/ && pip install -e . -q\n",
    "except Exception as e:\n",
    "    print(f'install error: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m<Hailo Model Zoo INFO> Start run for network mobilenet_v1 ...\u001b[0m\n",
      "\u001b[36m<Hailo Model Zoo INFO> \u001b[0m\n",
      "\ttask:                    classification\n",
      "\tinput_shape:             224x224x3\n",
      "\toutput_shape:            1001\n",
      "\toperations:              1.14G\n",
      "\tparameters:              4.22M\n",
      "\tframework:               tensorflow\n",
      "\ttraining_data:           imagenet train\n",
      "\tvalidation_data:         imagenet val\n",
      "\teval_metric:             Accuracy (top1)\n",
      "\tfull_precision_result:   70.97\n",
      "\tsource:                  https://github.com/tensorflow/models/tree/v1.13.0/research/slim\n",
      "\tlicense_url:             https://github.com/tensorflow/models/blob/master/LICENSE\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Check if HailoModel Zoo is installed \n",
    "\n",
    "! hailomz info mobilenet_v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Using HailoDFC and HailoModelZoo to compile ONNX model to HEF model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy your onnx model to hailo_model_zoo folder\n",
    "\n",
    "! cp ../../models/Chapter5/best.onnx ./hailo_model_zoo/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m<Hailo Model Zoo INFO> Start run for network yolov8n ...\u001b[0m\n",
      "\u001b[36m<Hailo Model Zoo INFO> Initializing the hailo8l runner...\u001b[0m\n",
      "[\u001b[32minfo\u001b[0m] Translation started on ONNX model yolov8n\n",
      "[\u001b[32minfo\u001b[0m] Restored ONNX model yolov8n (completion time: 00:00:00.06)\n",
      "[\u001b[32minfo\u001b[0m] Extracted ONNXRuntime meta-data for Hailo model (completion time: 00:00:00.22)\n",
      "[\u001b[32minfo\u001b[0m] NMS structure of yolov8 (or equivalent architecture) was detected.\n",
      "[\u001b[32minfo\u001b[0m] In order to use HailoRT post-processing capabilities, these end node names should be used: /model.22/cv2.0/cv2.0.2/Conv /model.22/cv3.0/cv3.0.2/Conv /model.22/cv2.1/cv2.1.2/Conv /model.22/cv3.1/cv3.1.2/Conv /model.22/cv2.2/cv2.2.2/Conv /model.22/cv3.2/cv3.2.2/Conv.\n",
      "[\u001b[32minfo\u001b[0m] Start nodes mapped from original model: 'images': 'yolov8n/input_layer1'.\n",
      "[\u001b[32minfo\u001b[0m] End nodes mapped from original model: '/model.22/cv2.0/cv2.0.2/Conv', '/model.22/cv3.0/cv3.0.2/Conv', '/model.22/cv2.1/cv2.1.2/Conv', '/model.22/cv3.1/cv3.1.2/Conv', '/model.22/cv2.2/cv2.2.2/Conv', '/model.22/cv3.2/cv3.2.2/Conv'.\n",
      "[\u001b[32minfo\u001b[0m] Translation completed on ONNX model yolov8n (completion time: 00:00:00.66)\n",
      "[\u001b[32minfo\u001b[0m] Saved HAR to: /home/jiahao/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/articles/Chapter_5-Custom_Model_Development_and_Deployment/hailo_model_zoo/yolov8n.har\n",
      "\u001b[36m<Hailo Model Zoo INFO> Using generic alls script found in /home/jiahao/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/articles/Chapter_5-Custom_Model_Development_and_Deployment/hailo_model_zoo/hailo_model_zoo/cfg/alls/generic/yolov8n.alls because there is no specific hardware alls\u001b[0m\n",
      "\u001b[36m<Hailo Model Zoo INFO> Preparing calibration data...\u001b[0m\n",
      "[\u001b[32minfo\u001b[0m] Loading model script commands to yolov8n from /home/jiahao/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/articles/Chapter_5-Custom_Model_Development_and_Deployment/hailo_model_zoo/hailo_model_zoo/cfg/alls/generic/yolov8n.alls\n",
      "[\u001b[32minfo\u001b[0m] Loading model script commands to yolov8n from string\n",
      "[\u001b[32minfo\u001b[0m] \u001b[32;1mStarting Model Optimization\u001b[0m\n",
      "[\u001b[33;1mwarning\u001b[0m] Reducing optimization level to 0 (the accuracy won't be optimized and compression won't be used) because there's less data than the recommended amount (1024), and there's no available GPU\n",
      "[\u001b[33;1mwarning\u001b[0m] Running model optimization with zero level of optimization is not recommended for production use and might lead to suboptimal accuracy results\n",
      "[\u001b[32minfo\u001b[0m] Model received quantization params from the hn\n",
      "[\u001b[32minfo\u001b[0m] Starting Mixed Precision\n",
      "[\u001b[32minfo\u001b[0m] Mixed Precision is done (completion time is 00:00:00.38)\n",
      "[\u001b[32minfo\u001b[0m] LayerNorm Decomposition skipped\n",
      "[\u001b[32minfo\u001b[0m] Starting Statistics Collector\n",
      "[\u001b[32minfo\u001b[0m] Using dataset with 64 entries for calibration\n",
      "Calibration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:26<00:00,  2.41entries/s]\n",
      "[\u001b[32minfo\u001b[0m] Statistics Collector is done (completion time is 00:00:28.09)\n",
      "[\u001b[32minfo\u001b[0m] Starting Fix zp_comp Encoding\n",
      "[\u001b[32minfo\u001b[0m] Fix zp_comp Encoding is done (completion time is 00:00:00.00)\n",
      "[\u001b[32minfo\u001b[0m] Matmul Equalization skipped\n",
      "[\u001b[32minfo\u001b[0m] No shifts available for layer yolov8n/conv59/conv_op, using max shift instead. delta=0.2111\n",
      "[\u001b[32minfo\u001b[0m] No shifts available for layer yolov8n/conv59/conv_op, using max shift instead. delta=0.1055\n",
      "[\u001b[32minfo\u001b[0m] Finetune encoding skipped\n",
      "[\u001b[32minfo\u001b[0m] Bias Correction skipped\n",
      "[\u001b[32minfo\u001b[0m] Adaround skipped\n",
      "[\u001b[32minfo\u001b[0m] Quantization-Aware Fine-Tuning skipped\n",
      "[\u001b[32minfo\u001b[0m] Layer Noise Analysis skipped\n",
      "[\u001b[32minfo\u001b[0m] \u001b[32;1mModel Optimization is done\u001b[0m\n",
      "[\u001b[32minfo\u001b[0m] Saved HAR to: /home/jiahao/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/articles/Chapter_5-Custom_Model_Development_and_Deployment/hailo_model_zoo/yolov8n.har\n",
      "\u001b[36m<Hailo Model Zoo INFO> Using generic alls script found in /home/jiahao/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/articles/Chapter_5-Custom_Model_Development_and_Deployment/hailo_model_zoo/hailo_model_zoo/cfg/alls/generic/yolov8n.alls because there is no specific hardware alls\u001b[0m\n",
      "[\u001b[32minfo\u001b[0m] Loading model script commands to yolov8n from /home/jiahao/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/articles/Chapter_5-Custom_Model_Development_and_Deployment/hailo_model_zoo/hailo_model_zoo/cfg/alls/generic/yolov8n.alls\n",
      "[\u001b[32minfo\u001b[0m] ParsedPerformanceParam command, setting optimization_level(max=2)\n",
      "[\u001b[32minfo\u001b[0m] Appending model script commands to yolov8n from string\n",
      "[\u001b[32minfo\u001b[0m] ParsedPerformanceParam command, setting optimization_level(max=2)\n",
      "[\u001b[32minfo\u001b[m] Loading network parameters\n",
      "[\u001b[32minfo\u001b[m] Starting Hailo allocation and compilation flow\n",
      "[\u001b[32minfo\u001b[m] Adding an output layer after conv41\n",
      "[\u001b[32minfo\u001b[m] Adding an output layer after conv42\n",
      "[\u001b[32minfo\u001b[m] Adding an output layer after conv52\n",
      "[\u001b[32minfo\u001b[m] Adding an output layer after conv53\n",
      "[\u001b[32minfo\u001b[m] Adding an output layer after conv62\n",
      "[\u001b[32minfo\u001b[m] Adding an output layer after conv63\n"
     ]
    }
   ],
   "source": [
    "# This command demonstrates converting a model into the HEF format supported by Hailo8L. If you are using Hailo8, please change \"Hailo8L\" to \"Hailo8\".\n",
    "# Your host computer at least have 32GB RAM.\n",
    "\n",
    "! cd hailo_model_zoo/ && python hailo_model_zoo/main.py compile yolov8n --ckpt best.onnx --hw-arch hailo8l  --calib-path /home/jiahao/datasets/train/images  --classes 3 --performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move yolov8n.hef to /models/Chapter5\n",
    "\n",
    "! mv   ./hailo_model_zoo/yolov8n.hef ../../models/Chapter5/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
