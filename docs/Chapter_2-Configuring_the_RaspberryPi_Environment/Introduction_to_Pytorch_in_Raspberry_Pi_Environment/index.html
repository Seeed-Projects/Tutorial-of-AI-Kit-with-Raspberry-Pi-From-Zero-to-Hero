<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-Chapter_2-Configuring_the_RaspberryPi_Environment/Introduction_to_Pytorch_in_Raspberry_Pi_Environment" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.0.1">
<title data-rh="true">Introduction to Pytorch in Raspberry Pi Environment | AI ❤️ Raspberry Pi</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://seeed-projects.github.io/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/img/social-card.png"><meta data-rh="true" name="twitter:image" content="https://seeed-projects.github.io/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/img/social-card.png"><meta data-rh="true" property="og:url" content="https://seeed-projects.github.io/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/docs/Chapter_2-Configuring_the_RaspberryPi_Environment/Introduction_to_Pytorch_in_Raspberry_Pi_Environment"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Introduction to Pytorch in Raspberry Pi Environment | AI ❤️ Raspberry Pi"><meta data-rh="true" name="description" content="What is PyTorch?"><meta data-rh="true" property="og:description" content="What is PyTorch?"><link data-rh="true" rel="icon" href="/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://seeed-projects.github.io/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/docs/Chapter_2-Configuring_the_RaspberryPi_Environment/Introduction_to_Pytorch_in_Raspberry_Pi_Environment"><link data-rh="true" rel="alternate" href="https://seeed-projects.github.io/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/docs/Chapter_2-Configuring_the_RaspberryPi_Environment/Introduction_to_Pytorch_in_Raspberry_Pi_Environment" hreflang="en"><link data-rh="true" rel="alternate" href="https://seeed-projects.github.io/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/docs/Chapter_2-Configuring_the_RaspberryPi_Environment/Introduction_to_Pytorch_in_Raspberry_Pi_Environment" hreflang="x-default"><link rel="stylesheet" href="/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/assets/css/styles.66020915.css">
<script src="/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/assets/js/runtime~main.8eb4b360.js" defer="defer"></script>
<script src="/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/assets/js/main.43389e34.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/"><div class="navbar__logo"><img src="/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/img/logo.png" alt="" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/img/logo.png" alt="" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">AI ❤️ Raspberry Pi</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/docs/Overview">Documentation</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/Seeed-Projects/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/blob/main/CONTRIBUTION.md" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Contributing<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><a href="https://github.com/Seeed-Projects/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/docs/Overview">Overview</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/docs/Chapter_1-Introduction_to_AI/">Chapter 1 - Introduction to AI</a><button aria-label="Expand sidebar category &#x27;Chapter 1 - Introduction to AI&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" aria-expanded="true" href="/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/docs/Chapter_2-Configuring_the_RaspberryPi_Environment/">Chapter 2 - Configuring the Raspberry Pi Environment</a><button aria-label="Collapse sidebar category &#x27;Chapter 2 - Configuring the Raspberry Pi Environment&#x27;" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/docs/Chapter_2-Configuring_the_RaspberryPi_Environment/Introduction_to_Pytorch_in_Raspberry_Pi_Environment">Introduction to Pytorch in Raspberry Pi Environment</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/docs/Chapter_2-Configuring_the_RaspberryPi_Environment/Introduction_to_TensorFlow_in_Raspberry_Pi_Environment">Introduction to TensorFlow in Raspberry Pi Environment</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/docs/Chapter_2-Configuring_the_RaspberryPi_Environment/Introduction_to_OpenCV">Introduction to OpenCV in Raspberry Pi Environment</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/docs/Chapter_2-Configuring_the_RaspberryPi_Environment/Introduction_to_Ultralytics_in_Raspberry_Pi_Environment">Introduction to Ultralytics in Raspberry Pi Environment</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/docs/Chapter_2-Configuring_the_RaspberryPi_Environment/Introduction_to_Hailo_in_Raspberry_Pi_Environment">Introduction to Hailo in Raspberry Pi Environment</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/docs/Chapter_3-Computer_Vision_Projects_and_Practical_Applications/">Chapter 3 - Computer Vision Projects and Practical Applications</a><button aria-label="Expand sidebar category &#x27;Chapter 3 - Computer Vision Projects and Practical Applications&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/docs/Chapter_4-Large_Language_Model/">Chapter 4 - Large Language Model</a><button aria-label="Expand sidebar category &#x27;Chapter 4 - Large Language Model&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/docs/Chapter_5-Custom_Model_Development_and_Deployment/">Chapter 5 - Custom Model Development and Deployment</a><button aria-label="Expand sidebar category &#x27;Chapter 5 - Custom Model Development and Deployment&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/docs/Chapter_6-RaspberryPi_and_AIoT/">Chapter 6 - Raspberry Pi and AIoT</a><button aria-label="Expand sidebar category &#x27;Chapter 6 - Raspberry Pi and AIoT&#x27;" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/docs/Chapter_2-Configuring_the_RaspberryPi_Environment/"><span itemprop="name">Chapter 2 - Configuring the Raspberry Pi Environment</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Introduction to Pytorch in Raspberry Pi Environment</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>Introduction to Pytorch in Raspberry Pi Environment</h1>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="what-is-pytorch">What is PyTorch?<a href="#what-is-pytorch" class="hash-link" aria-label="Direct link to What is PyTorch?" title="Direct link to What is PyTorch?">​</a></h2>
<p><img loading="lazy" alt="pytorchlogo" src="data:image/svg+xml;base64,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" width="2500" height="1250" class="img_ev3q"></p>
<p>PyTorch is an open-source machine learning framework developed by Facebook&#x27;s AI Research lab (FAIR). It is known for its flexibility, dynamic computation graphs, and strong community support. PyTorch simplifies the development of deep learning models, making it a popular choice for researchers and practitioners alike.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="brief-history">Brief History<a href="#brief-history" class="hash-link" aria-label="Direct link to Brief History" title="Direct link to Brief History">​</a></h3>
<ul>
<li>
<p><strong>2016</strong>: PyTorch was released by Facebook as an open-source library, combining features of Torch (a Lua-based framework) and Python for easy usability.</p>
</li>
<li>
<p><strong>2019</strong>: Gained significant momentum when Facebook partnered with Microsoft to create ONNX (Open Neural Network Exchange) for model interoperability.</p>
</li>
<li>
<p><strong>2022</strong>: PyTorch became part of the PyTorch Foundation, ensuring community-driven development.</p>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="why-use-pytorch">Why Use PyTorch?<a href="#why-use-pytorch" class="hash-link" aria-label="Direct link to Why Use PyTorch?" title="Direct link to Why Use PyTorch?">​</a></h3>
<ul>
<li>
<p><strong>Dynamic Graphs</strong>: PyTorch uses dynamic computation graphs, allowing flexibility in building and debugging models.</p>
</li>
<li>
<p><strong>Pythonic</strong>: Integrates seamlessly with Python, making it intuitive for Python developers.</p>
</li>
<li>
<p><strong>Community Support</strong>: A vibrant ecosystem with numerous tutorials, forums, and open-source projects.</p>
</li>
<li>
<p><strong>Accelerated Research</strong>: Its ease of use accelerates model experimentation and implementation.</p>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="what-are-dynamic-computation-graphs">What Are Dynamic Computation Graphs?<a href="#what-are-dynamic-computation-graphs" class="hash-link" aria-label="Direct link to What Are Dynamic Computation Graphs?" title="Direct link to What Are Dynamic Computation Graphs?">​</a></h3>
<ul>
<li>A computation graph represents the operations performed on data (e.g., tensors) in a deep learning model.</li>
<li>Dynamic Graphs (PyTorch)<!-- -->:The<!-- --> computation graph is built on the fly as operations are executed.<!-- -->
<ul>
<li>Each forward pass can construct a different graph, allowing for greater flexibility and adaptability.</li>
<li>You don’t need to define the entire graph beforehand; it evolves during runtime.</li>
</ul>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="who-uses-pytorch">Who Uses PyTorch?<a href="#who-uses-pytorch" class="hash-link" aria-label="Direct link to Who Uses PyTorch?" title="Direct link to Who Uses PyTorch?">​</a></h3>
<ul>
<li>
<p><strong>Research Organizations</strong>: MIT, Stanford, OpenAI, and FAIR.</p>
</li>
<li>
<p><strong>Companies</strong>: Facebook (Meta), Tesla (autonomous driving), Disney (AI for animation), and Microsoft.</p>
</li>
<li>
<p><strong>Domains</strong>: Used in computer vision, natural language processing, reinforcement learning, and more.</p>
</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="pytorch-vs-tensorflow-feature-comparison">PyTorch vs TensorFlow: Feature Comparison<a href="#pytorch-vs-tensorflow-feature-comparison" class="hash-link" aria-label="Direct link to PyTorch vs TensorFlow: Feature Comparison" title="Direct link to PyTorch vs TensorFlow: Feature Comparison">​</a></h2>
<p><img loading="lazy" alt="pytorchvstf" src="/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/assets/images/tfvstorch-5bc564f84587b3f93726ab5e2a299eb3.PNG" width="1461" height="766" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="pytorch-vs-tensorflow-feature-comparison-1">PyTorch vs TensorFlow: Feature Comparison<a href="#pytorch-vs-tensorflow-feature-comparison-1" class="hash-link" aria-label="Direct link to PyTorch vs TensorFlow: Feature Comparison" title="Direct link to PyTorch vs TensorFlow: Feature Comparison">​</a></h2>
<table><thead><tr><th><strong>Feature</strong></th><th><strong>PyTorch</strong></th><th><strong>TensorFlow</strong></th></tr></thead><tbody><tr><td><strong>Computation Graph</strong></td><td>Dynamic (easier for debugging)</td><td>Static (optimized for deployment)</td></tr><tr><td><strong>Ease of Use</strong></td><td>Intuitive and Pythonic</td><td>Requires a steeper learning curve</td></tr><tr><td><strong>Community</strong></td><td>Popular in academia and research</td><td>Widely used in production and enterprises</td></tr><tr><td><strong>Frameworks Built On</strong></td><td>Lightning, Detectron2, Hugging Face</td><td>Keras, TFX, TensorFlow Lite</td></tr><tr><td><strong>Deployment</strong></td><td>TorchServe, ONNX</td><td>TensorFlow Serving, TensorFlow.js</td></tr><tr><td><strong>Performance</strong></td><td>Efficient but depends on optimization</td><td>Better optimization for large-scale tasks</td></tr></tbody></table>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="what-is-qnnpack">What is QNNPACK?<a href="#what-is-qnnpack" class="hash-link" aria-label="Direct link to What is QNNPACK?" title="Direct link to What is QNNPACK?">​</a></h2>
<p>QNNPACK (Quantized Neural Network PACKage) is a high-performance kernel library developed by Facebook for running quantized neural networks efficiently on ARM CPUs. It is optimized for low-power devices, such as mobile phones and Raspberry Pi, and is a critical component for executing PyTorch&#x27;s quantized models. It supports operations like convolutions, fully connected layers, and more, tailored for low-precision inference.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="setting-up-the-environment-for-pytorch-classification">Setting Up the Environment for PyTorch Classification<a href="#setting-up-the-environment-for-pytorch-classification" class="hash-link" aria-label="Direct link to Setting Up the Environment for PyTorch Classification" title="Direct link to Setting Up the Environment for PyTorch Classification">​</a></h2>
<p><strong>Create a Virtual Environment</strong></p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">mkdir my_pytorch_course</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cd my_pytorch_course</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">python -m venv --system-site-packages env</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">source env/bin/activate</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p><strong>Install Required Libraries</strong></p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">pip install torch torchvision torchaudio opencv-python numpy</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p><strong>Prepare Your Directory</strong></p>
<ul>
<li>Create a folder on your Desktop named pytorch.</li>
<li>Inside the pytorch folder, create the following files:<!-- -->
<ul>
<li>pytorch_test.py (for your Python code).</li>
<li>imagenet-classes.txt (contains ImageNet class labels).</li>
</ul>
</li>
</ul>
<p><img loading="lazy" alt="folder" src="/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/assets/images/folder_torch-60a79a6463bbf4d087db0c134240b68c.PNG" width="1027" height="776" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="python-code-pytorch_testpy">Python Code (pytorch_test.py)<a href="#python-code-pytorch_testpy" class="hash-link" aria-label="Direct link to Python Code (pytorch_test.py)" title="Direct link to Python Code (pytorch_test.py)">​</a></h2>
<p>Copy the provided Python code into the file pytorch_test.py:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">import time</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import torch</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import numpy as np</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from torchvision import models, transforms</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import cv2</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from PIL import Image</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">torch.set_num_threads(torch.get_num_threads())</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Ensure qnnpack backend is used for quantized models</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">torch.backends.quantized.engine = &#x27;qnnpack&#x27;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Load the ImageNet class labels</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">with open(&quot;imagenet-classes.txt&quot;, &quot;r&quot;) as f:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    classes = [line.strip() for line in f.readlines()]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Initialize webcam</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cap = cv2.VideoCapture(0, cv2.CAP_V4L2)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cap.set(cv2.CAP_PROP_FRAME_WIDTH, 224)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 224)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cap.set(cv2.CAP_PROP_FPS, 36)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Preprocessing pipeline</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">preprocess = transforms.Compose([</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    transforms.ToTensor(),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">])</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Load MobileNetV2 quantized model</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">net = models.quantization.mobilenet_v2(pretrained=True, quantize=True)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">net = torch.jit.script(net)  # Optimize model for inference</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Performance logging</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">started = time.time()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">last_logged = time.time()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">frame_count = 0</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Real-time inference</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">with torch.no_grad():</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    while True:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # Read frame from webcam</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        ret, frame = cap.read()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        if not ret:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            print(&quot;Failed to capture frame. Exiting...&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            break</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # Convert BGR to RGB</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # Preprocess image</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        input_tensor = preprocess(image)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        input_batch = input_tensor.unsqueeze(0)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # Perform inference</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        output = net(input_batch)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        probabilities = output[0].softmax(dim=0)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # Get top-10 predictions</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        top = list(enumerate(probabilities))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        top.sort(key=lambda x: x[1], reverse=True)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        top_predictions = [(classes[idx], val.item()) for idx, val in top[:3]]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # Display predictions on the frame</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        for i, (label, prob) in enumerate(top_predictions):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            text = f&quot;{prob * 100:.2f}% {label}&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            cv2.putText(frame, text, (10, 25 + i * 20), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # Show the frame</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        cv2.imshow(&quot;Real-time Object Recognition&quot;, frame)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # Log fps</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        frame_count += 1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        now = time.time()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        if now - last_logged &gt; 1:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            print(f&quot;{frame_count / (now - last_logged):.2f} fps&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            last_logged = now</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            frame_count = 0</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # Exit on pressing &#x27;q&#x27;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        if cv2.waitKey(1) &amp; 0xFF == ord(&#x27;q&#x27;):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            break</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Release resources</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cap.release()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cv2.destroyAllWindows()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="how-to-run-the-code">How to Run the Code<a href="#how-to-run-the-code" class="hash-link" aria-label="Direct link to How to Run the Code" title="Direct link to How to Run the Code">​</a></h2>
<p><strong>Navigate to the pytorch directory</strong></p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">cd /home/pi/Desktop/pytorch</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p><strong>Run the Python script</strong></p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">python pytorch_test.py</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p><strong>Check Output</strong></p>
<p>A window will open showing the real-time webcam feed.The top-3 predictions (with confidence percentages) will be displayed on the video feed.</p>
<p><img loading="lazy" alt="result" src="/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/assets/images/torch_results-d9341f4cbf8c44c75e1dbbfb674a12a5.PNG" width="1022" height="730" class="img_ev3q"></p>
<p>Futher references :</p>
<p><a href="https://pytorch.org/docs/stable/index.html" target="_blank" rel="noopener noreferrer">Pytorch Documentation</a></p>
<p><a href="https://www.learnpytorch.io/" target="_blank" rel="noopener noreferrer">Pytorch Course</a></p></div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/docs/Chapter_2-Configuring_the_RaspberryPi_Environment/"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Chapter 2 - Configuring the Raspberry Pi Environment</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/docs/Chapter_2-Configuring_the_RaspberryPi_Environment/Introduction_to_TensorFlow_in_Raspberry_Pi_Environment"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Introduction to TensorFlow in Raspberry Pi Environment</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#what-is-pytorch" class="table-of-contents__link toc-highlight">What is PyTorch?</a><ul><li><a href="#brief-history" class="table-of-contents__link toc-highlight">Brief History</a></li><li><a href="#why-use-pytorch" class="table-of-contents__link toc-highlight">Why Use PyTorch?</a></li><li><a href="#what-are-dynamic-computation-graphs" class="table-of-contents__link toc-highlight">What Are Dynamic Computation Graphs?</a></li><li><a href="#who-uses-pytorch" class="table-of-contents__link toc-highlight">Who Uses PyTorch?</a></li></ul></li><li><a href="#pytorch-vs-tensorflow-feature-comparison" class="table-of-contents__link toc-highlight">PyTorch vs TensorFlow: Feature Comparison</a></li><li><a href="#pytorch-vs-tensorflow-feature-comparison-1" class="table-of-contents__link toc-highlight">PyTorch vs TensorFlow: Feature Comparison</a></li><li><a href="#what-is-qnnpack" class="table-of-contents__link toc-highlight">What is QNNPACK?</a></li><li><a href="#setting-up-the-environment-for-pytorch-classification" class="table-of-contents__link toc-highlight">Setting Up the Environment for PyTorch Classification</a></li><li><a href="#python-code-pytorch_testpy" class="table-of-contents__link toc-highlight">Python Code (pytorch_test.py)</a></li><li><a href="#how-to-run-the-code" class="table-of-contents__link toc-highlight">How to Run the Code</a></li></ul></div></div></div></div></main></div></div></div><footer class="footer"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">© 2025 Seeed Studio. All Rights Reserved.</div></div></div></footer></div>
</body>
</html>