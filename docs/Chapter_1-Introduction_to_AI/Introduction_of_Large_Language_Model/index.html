<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-Chapter_1-Introduction_to_AI/Introduction_of_Large_Language_Model" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.0.1">
<title data-rh="true">Generative AI (GenAI) | AI ❤️ Raspberry Pi</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://seeed-projects.github.io/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/img/social-card.png"><meta data-rh="true" name="twitter:image" content="https://seeed-projects.github.io/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/img/social-card.png"><meta data-rh="true" property="og:url" content="https://seeed-projects.github.io/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/docs/Chapter_1-Introduction_to_AI/Introduction_of_Large_Language_Model"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Generative AI (GenAI) | AI ❤️ Raspberry Pi"><meta data-rh="true" name="description" content="Generative AI is an artificial intelligence system capable of creating new, original content across various mediums such as text, images, audio, and video. These systems learn patterns from existing data and use that knowledge to generate novel outputs that didn&#x27;t previously exist. Large Language Models (LLMs), Small Language Models (SLMs), and multimodal models can all be considered types of GenAI when used for generative tasks."><meta data-rh="true" property="og:description" content="Generative AI is an artificial intelligence system capable of creating new, original content across various mediums such as text, images, audio, and video. These systems learn patterns from existing data and use that knowledge to generate novel outputs that didn&#x27;t previously exist. Large Language Models (LLMs), Small Language Models (SLMs), and multimodal models can all be considered types of GenAI when used for generative tasks."><link data-rh="true" rel="icon" href="/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://seeed-projects.github.io/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/docs/Chapter_1-Introduction_to_AI/Introduction_of_Large_Language_Model"><link data-rh="true" rel="alternate" href="https://seeed-projects.github.io/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/docs/Chapter_1-Introduction_to_AI/Introduction_of_Large_Language_Model" hreflang="en"><link data-rh="true" rel="alternate" href="https://seeed-projects.github.io/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/docs/Chapter_1-Introduction_to_AI/Introduction_of_Large_Language_Model" hreflang="x-default"><link rel="stylesheet" href="/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/assets/css/styles.66020915.css">
<script src="/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/assets/js/runtime~main.acb60faa.js" defer="defer"></script>
<script src="/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/assets/js/main.c3437ae6.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/"><div class="navbar__logo"><img src="/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/img/logo.png" alt="" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/img/logo.png" alt="" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">AI ❤️ Raspberry Pi</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/docs/Overview">Documentation</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/Seeed-Projects/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/blob/main/CONTRIBUTION.md" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Contributing<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><a href="https://github.com/Seeed-Projects/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/docs/Overview">Overview</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" href="/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/docs/Chapter_1-Introduction_to_AI/Introduction_of_Artificial_Intelligence">Chapter_1-Introduction_to_AI</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/docs/Chapter_1-Introduction_to_AI/Introduction_of_Artificial_Intelligence">Introduction of Artificial Intelligence</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/docs/Chapter_1-Introduction_to_AI/Introduction_to_Deep_Neural_Network">Introduction to DNN</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/docs/Chapter_1-Introduction_to_AI/Introduction_of_Convolutional_Neural_Network">Introduction of Convolutional Neural Network</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/docs/Chapter_1-Introduction_to_AI/Introduction_of_Computer_Vision">Mastering Computer Vision with Seeed Studio</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/docs/Chapter_1-Introduction_to_AI/Introduction_of_Large_Language_Model">Generative AI (GenAI)</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/docs/Chapter_2-Configuring_the_RaspberryPi_Environment/Introduction_to_Pytorch_in_Raspberry_Pi_Environment">Chapter_2-Configuring_the_RaspberryPi_Environment</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/docs/Chapter_4-Large_Language_Model/Setup_Ollama_on_RaspberryPi">Chapter_4-Large_Language_Model</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/docs/Chapter_5-Custom_Model_Development_and_Deployment/Training_Your_Model">Chapter_5-Custom_Model_Development_and_Deployment</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/docs/Chapter_6-RaspberryPi_and_AIoT/Retrieval_Augmented_Generation_Project">Chapter_6-RaspberryPi_and_AIoT</a></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Chapter_1-Introduction_to_AI</span><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Generative AI (GenAI)</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>Generative AI (GenAI)</h1>
<p>Generative AI is an artificial intelligence system capable of creating new, original content across various mediums such as <strong>text, images, audio, and video</strong>. These systems learn patterns from existing data and use that knowledge to generate novel outputs that didn&#x27;t previously exist. <strong>Large Language Models (LLMs)</strong>, <strong>Small Language Models (SLMs)</strong>, and <strong>multimodal models</strong> can all be considered types of GenAI when used for generative tasks.</p>
<p>GenAI provides the conceptual framework for AI-driven content creation, with LLMs serving as powerful general-purpose text generators. SLMs adapt this technology for edge computing, while multimodal models extend GenAI capabilities across different data types. Together, they represent a spectrum of generative AI technologies, each with its strengths and applications, collectively driving AI-powered content creation and understanding.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="large-language-models-llms">Large Language Models (LLMs)<a href="#large-language-models-llms" class="hash-link" aria-label="Direct link to Large Language Models (LLMs)" title="Direct link to Large Language Models (LLMs)">​</a></h2>
<p>Large Language Models (LLMs) are advanced artificial intelligence systems that understand, process, and generate human-like text. These models are characterized by their massive scale in terms of the amount of data they are trained on and the number of parameters they contain. Critical aspects of LLMs include:</p>
<ol>
<li>
<p><strong>Size</strong>: LLMs typically contain billions of parameters. For example, GPT-3 has 175 billion parameters, while some newer models exceed a trillion parameters.</p>
</li>
<li>
<p><strong>Training Data</strong>: They are trained on vast amounts of text data, often including books, websites, and other diverse sources, amounting to hundreds of gigabytes or even terabytes of text.</p>
</li>
<li>
<p><strong>Architecture</strong>: Most LLMs use <a href="https://en.wikipedia.org/wiki/Transformer_(deep_learning_architecture)" target="_blank" rel="noopener noreferrer">transformer-based architectures</a>, which allow them to process and generate text by paying attention to different parts of the input simultaneously.</p>
</li>
<li>
<p><strong>Capabilities</strong>: LLMs can perform a wide range of language tasks without specific fine-tuning, including:</p>
<ul>
<li>Text generation</li>
<li>Translation</li>
<li>Summarization</li>
<li>Question answering</li>
<li>Code generation</li>
<li>Logical reasoning</li>
</ul>
</li>
<li>
<p><strong>Few-shot Learning</strong>: They can often understand and perform new tasks with minimal examples or instructions.</p>
</li>
<li>
<p><strong>Resource-Intensive</strong>: Due to their size, LLMs typically require significant computational resources to run, often needing powerful GPUs or TPUs.</p>
</li>
<li>
<p><strong>Continual Development</strong>: The field of LLMs is rapidly evolving, with new models and techniques constantly emerging.</p>
</li>
<li>
<p><strong>Ethical Considerations</strong>: The use of LLMs raises important questions about bias, misinformation, and the environmental impact of training such large models.</p>
</li>
<li>
<p><strong>Applications</strong>: LLMs are used in various fields, including content creation, customer service, research assistance, and software development.</p>
</li>
<li>
<p><strong>Limitations</strong>: Despite their power, LLMs can produce incorrect or biased information and lack true understanding or reasoning capabilities.</p>
</li>
</ol>
<p>We must note that we use large models beyond text, calling them <em>multi-modal models</em>. These models integrate and process information from multiple types of input simultaneously. They are designed to understand and generate content across various forms of data, such as text, images, audio, and video.</p>
<p>Certainly. Let&#x27;s define open and closed models in the context of AI and language models:</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="closed-vs-open-models">Closed vs Open Models:<a href="#closed-vs-open-models" class="hash-link" aria-label="Direct link to Closed vs Open Models:" title="Direct link to Closed vs Open Models:">​</a></h2>
<p><strong>Closed models</strong>, also called proprietary models, are AI models whose internal workings, code, and training data are not publicly disclosed. Examples: GPT-4 (by OpenAI), Claude (by Anthropic), Gemini (by Google).</p>
<p><strong>Open models</strong>, also known as open-source models, are AI models whose underlying code, architecture, and often training data are publicly available and accessible. Examples: Gemma (by Google), LLaMA (by Meta) and Phi (by Microsoft)/</p>
<p>Open models are particularly relevant for running models on edge devices like Raspberry Pi as they can be more easily adapted, optimized, and deployed in resource-constrained environments. Still, it is crucial to verify their Licenses. Open models come with various open-source licenses that may affect their use in commercial applications, while closed models have clear, albeit restrictive, terms of service.</p>
<p><img loading="lazy" alt="Adapted from https://arxiv.org/pdf/2304.13712" src="/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/assets/images/llms-slm-e8a9a3b6a81e015876463540afbda1d3.png" width="1794" height="906" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="small-language-models-slms">Small Language Models (SLMs)<a href="#small-language-models-slms" class="hash-link" aria-label="Direct link to Small Language Models (SLMs)" title="Direct link to Small Language Models (SLMs)">​</a></h2>
<p>In the context of edge computing on devices like Raspberry Pi, full-scale LLMs are typically too large and resource-intensive to run directly. This limitation has driven the development of smaller, more efficient models, such as the Small Language Models (SLMs).</p>
<p>SLMs are compact versions of LLMs designed to run efficiently on resource-constrained devices such as smartphones, IoT devices, and single-board computers like the Raspberry Pi. These models are significantly smaller in size and computational requirements than their larger counterparts while still retaining impressive language understanding and generation capabilities.</p>
<p>Key characteristics of SLMs include:</p>
<ol>
<li>
<p><strong>Reduced parameter count</strong>: Typically ranging from a few hundred million to a few billion parameters, compared to two-digit billions in larger models.</p>
</li>
<li>
<p><strong>Lower memory footprint</strong>: Requiring, at most, a few gigabytes of memory rather than tens or hundreds of gigabytes.</p>
</li>
<li>
<p><strong>Faster inference time</strong>: Can generate responses in milliseconds to seconds on edge devices.</p>
</li>
<li>
<p><strong>Energy efficiency</strong>: Consuming less power, making them suitable for battery-powered devices.</p>
</li>
<li>
<p><strong>Privacy-preserving</strong>: Enabling on-device processing without sending data to cloud servers.</p>
</li>
<li>
<p><strong>Offline functionality</strong>: Operating without an internet connection.</p>
</li>
</ol>
<p>SLMs achieve their compact size through various techniques such as knowledge distillation, model pruning, and quantization. While they may not match the broad capabilities of larger models, SLMs excel in specific tasks and domains, making them ideal for targeted applications on edge devices.</p>
<blockquote>
<p>We will generally consider SLMs, language models with less than 5 billion parameters quantized to 4 bits.</p>
</blockquote>
<p>Examples of SLMs include compressed versions of models like Meta Llama, Microsoft PHI, and Google Gemma. These models enable a wide range of natural language processing tasks directly on edge devices, from text classification and sentiment analysis to question answering and limited text generation.</p>
<p>For more information on SLMs, the paper, <a href="https://arxiv.org/pdf/2408.11796" target="_blank" rel="noopener noreferrer">LLM Pruning and Distillation in Practice: The Minitron Approach</a>, provides an approach applying pruning and distillation to obtain SLMs from LLMs. And, <a href="https://arxiv.org/pdf/2409.15790" target="_blank" rel="noopener noreferrer">SMALL LANGUAGE MODELS: SURVEY, MEASUREMENTS, AND INSIGHTS</a>, presents a comprehensive survey and analysis of Small Language Models (SLMs), which are language models with 100 million to 5 billion parameters designed for resource-constrained devices.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="conclusion">Conclusion<a href="#conclusion" class="hash-link" aria-label="Direct link to Conclusion" title="Direct link to Conclusion">​</a></h2>
<p>This chapter introduces some basic concepts of large language models. And The potential of running LLMs on the edge extends far beyond simple data processing, as in this lab&#x27;s examples. Here are some innovative suggestions for using this project:</p>
<p><strong>1. Smart Home Automation:</strong></p>
<ul>
<li>Integrate SLMs to interpret voice commands or analyze sensor data for intelligent home automation. This could include real-time monitoring and control of home devices, security systems, and energy management, all processed locally without relying on cloud services.</li>
</ul>
<p><strong>2. Field Data Collection and Analysis:</strong></p>
<ul>
<li>Deploy SLMs on Raspberry Pi in remote or mobile setups for real-time data collection and analysis. This can be used in agriculture to monitor crop health, in environmental studies for wildlife tracking, or in disaster response for situational awareness and resource management.</li>
</ul>
<p><strong>3. Educational Tools:</strong></p>
<ul>
<li>Create interactive educational tools that leverage SLMs to provide instant feedback, language translation, and tutoring. This can be particularly useful in developing regions with limited access to advanced technology and internet connectivity.</li>
</ul>
<p><strong>4. Healthcare Applications:</strong></p>
<ul>
<li>Use SLMs for medical diagnostics and patient monitoring. They can provide real-time analysis of symptoms and suggest potential treatments. This can be integrated into telemedicine platforms or portable health devices.</li>
</ul>
<p><strong>5. Local Business Intelligence:</strong></p>
<ul>
<li>Implement SLMs in retail or small business environments to analyze customer behavior, manage inventory, and optimize operations. The ability to process data locally ensures privacy and reduces dependency on external services.</li>
</ul>
<p><strong>6. Industrial IoT:</strong></p>
<ul>
<li>Integrate SLMs into industrial IoT systems for predictive maintenance, quality control, and process optimization. The Raspberry Pi can serve as a localized data processing unit, reducing latency and improving the reliability of automated systems.</li>
</ul>
<p><strong>7. Autonomous Vehicles:</strong></p>
<ul>
<li>Use SLMs to process sensory data from autonomous vehicles, enabling real-time decision-making and navigation. This can be applied to drones, robots, and self-driving cars for enhanced autonomy and safety.</li>
</ul>
<p><strong>8. Cultural Heritage and Tourism:</strong></p>
<ul>
<li>Implement SLMs to provide interactive and informative cultural heritage sites and museum guides. Visitors can use these systems to get real-time information and insights, enhancing their experience without internet connectivity.</li>
</ul>
<p><strong>9. Artistic and Creative Projects:</strong></p>
<ul>
<li>Use SLMs to analyze and generate creative content, such as music, art, and literature. This can foster innovative projects in the creative industries and allow for unique interactive experiences in exhibitions and performances.</li>
</ul>
<p><strong>10. Customized Assistive Technologies:</strong></p>
<ul>
<li>Develop assistive technologies for individuals with disabilities, providing personalized and adaptive support through real-time text-to-speech, language translation, and other accessible tools.</li>
</ul></div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/docs/Chapter_1-Introduction_to_AI/Introduction_of_Computer_Vision"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Mastering Computer Vision with Seeed Studio</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/docs/Chapter_2-Configuring_the_RaspberryPi_Environment/Introduction_to_Pytorch_in_Raspberry_Pi_Environment"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Introduction to Pytorch in Raspberry Pi Environment</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#large-language-models-llms" class="table-of-contents__link toc-highlight">Large Language Models (LLMs)</a></li><li><a href="#closed-vs-open-models" class="table-of-contents__link toc-highlight">Closed vs Open Models:</a></li><li><a href="#small-language-models-slms" class="table-of-contents__link toc-highlight">Small Language Models (SLMs)</a></li><li><a href="#conclusion" class="table-of-contents__link toc-highlight">Conclusion</a></li></ul></div></div></div></div></main></div></div></div><footer class="footer"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">© 2024 Seeed Studio. All Rights Reserved.</div></div></div></footer></div>
</body>
</html>