"use strict";(self.webpackChunktutorial_of_ai_kit=self.webpackChunktutorial_of_ai_kit||[]).push([[356],{8779:(e,o,t)=>{t.r(o),t.d(o,{assets:()=>l,contentTitle:()=>a,default:()=>p,frontMatter:()=>r,metadata:()=>s,toc:()=>d});var n=t(5893),i=t(1151);const r={sidebar_position:1},a=void 0,s={id:"Chapter 5 - Custom Model Development and Deployment/Training Your Model",title:"Training Your Model",description:"You can get this Notebook on GitHub.",source:"@site/../articles/Chapter 5 - Custom Model Development and Deployment/Training Your Model.md",sourceDirName:"Chapter 5 - Custom Model Development and Deployment",slug:"/Chapter 5 - Custom Model Development and Deployment/Training Your Model",permalink:"/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/docs/Chapter 5 - Custom Model Development and Deployment/Training Your Model",draft:!1,unlisted:!1,tags:[],version:"current",sidebarPosition:1,frontMatter:{sidebar_position:1},sidebar:"tutorialSidebar",previous:{title:"Introduction to OpenCV in Raspberry Pi Environment",permalink:"/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/docs/Chapter 1 - Introduction to AI/Introduction_to_OpenCV"},next:{title:"Convert Your Model",permalink:"/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/docs/Chapter 5 - Custom Model Development and Deployment/Convert Your Model"}},l={},d=[{value:"Step 1: Prepare you environment on your host computer",id:"step-1-prepare-you-environment-on-your-host-computer",level:2},{value:"Step 2: Prepare your dateset",id:"step-2-prepare-your-dateset",level:2},{value:"Step 1: Create Project",id:"step-1-create-project",level:3},{value:"Step 2: Update images and annotate",id:"step-2-update-images-and-annotate",level:3},{value:"Step 3: Export dataset",id:"step-3-export-dataset",level:3},{value:"Step 3: Training Yolo11n",id:"step-3-training-yolo11n",level:2},{value:"Step 4: Export to ONNX format",id:"step-4-export-to-onnx-format",level:2}];function c(e){const o={a:"a",blockquote:"blockquote",code:"code",h2:"h2",h3:"h3",img:"img",p:"p",pre:"pre",strong:"strong",...(0,i.a)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsxs)(o.blockquote,{children:["\n",(0,n.jsxs)(o.p,{children:["You can get this ",(0,n.jsx)(o.a,{href:"https://github.com/Seeed-Projects/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/blob/main/articles/Chapter%205%20-%20Custom%20Model%20Development%20and%20Deployment/Training%20Your%20Model.ipynb",children:"Notebook"})," on GitHub."]}),"\n"]}),"\n",(0,n.jsx)(o.h2,{id:"step-1-prepare-you-environment-on-your-host-computer",children:"Step 1: Prepare you environment on your host computer"}),"\n",(0,n.jsx)(o.p,{children:(0,n.jsx)(o.strong,{children:"Note\uff1aThis part of code run on your host computer"})}),"\n",(0,n.jsxs)(o.p,{children:["The Jupyter Notebook right up have a button like ",(0,n.jsx)(o.img,{alt:"select kernel",src:t(5260).Z+"",width:"113",height:"23"}),", then you choose ",(0,n.jsx)(o.code,{children:"Select Another Kernel"}),", and choose ",(0,n.jsx)(o.code,{children:"Python Environments"}),", then choose ",(0,n.jsx)(o.code,{children:"Creat Python Environment"})," and choose ",(0,n.jsx)(o.code,{children:"Venv"}),", then choose ",(0,n.jsx)(o.code,{children:"python3.10"}),"."]}),"\n",(0,n.jsx)(o.pre,{children:(0,n.jsx)(o.code,{className:"language-python",children:"# Here is my hostcomputer information, you should install Ubantu 22.04 if you what use this code.\n# Linux PC 6.8.0-45-generic #45~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Sep 11 15:25:05 UTC 2 x86_64 x86_64 x86_64 GNU/Linux.\n\n!uname -a\n"})}),"\n",(0,n.jsx)(o.pre,{children:(0,n.jsx)(o.code,{className:"language-python",children:"# Here is my python version, you should install python3.10.12 \n# Python 3.10.12\n\n!python -V\n"})}),"\n",(0,n.jsx)(o.pre,{children:(0,n.jsx)(o.code,{className:"language-python",children:"# Install libs, if you see 'install successfully' it means you install libs successfully, or when you see 'install error' it means you install libs unsuccessfully\ntry:\n    %pip install torch torchvision pycocotools opencv-python ultralytics matplotlib -q\n    print('install successfully')\nexcept:\n    print('install error')\n\n"})}),"\n",(0,n.jsx)(o.h2,{id:"step-2-prepare-your-dateset",children:"Step 2: Prepare your dateset"}),"\n",(0,n.jsxs)(o.p,{children:["I want to build a model to detect different fruit include banana, apple and orange. So I need to collect some pictures of this fruit. And I use ",(0,n.jsx)(o.a,{href:"https://roboflow.com/",children:"robflow"})," to label my dataset."]}),"\n",(0,n.jsx)(o.h3,{id:"step-1-create-project",children:"Step 1: Create Project"}),"\n",(0,n.jsxs)(o.p,{children:["Select ",(0,n.jsx)(o.code,{children:"New Project"}),":"]}),"\n",(0,n.jsx)(o.p,{children:(0,n.jsx)(o.img,{alt:"roboflow_1",src:t(9387).Z+"",width:"1713",height:"796"})}),"\n",(0,n.jsx)(o.p,{children:"Fill your project information and create the project"}),"\n",(0,n.jsx)(o.p,{children:(0,n.jsx)(o.img,{alt:"roboflow_2",src:t(8806).Z+"",width:"1717",height:"801"})}),"\n",(0,n.jsx)(o.h3,{id:"step-2-update-images-and-annotate",children:"Step 2: Update images and annotate"}),"\n",(0,n.jsx)(o.p,{children:"Update images"}),"\n",(0,n.jsx)(o.p,{children:(0,n.jsx)(o.img,{alt:"roboflow_3",src:t(9918).Z+"",width:"1698",height:"792"})}),"\n",(0,n.jsx)(o.p,{children:"Label your image"}),"\n",(0,n.jsx)(o.p,{children:(0,n.jsx)(o.img,{alt:"roboflow_4",src:t(3837).Z+"",width:"1708",height:"791"})}),"\n",(0,n.jsx)(o.h3,{id:"step-3-export-dataset",children:"Step 3: Export dataset"}),"\n",(0,n.jsx)(o.p,{children:"Add annotated image to your dataset"}),"\n",(0,n.jsx)(o.p,{children:(0,n.jsx)(o.img,{alt:"roboflow_5",src:t(5121).Z+"",width:"1714",height:"794"})}),"\n",(0,n.jsx)(o.p,{children:"Generate New version of your dataset"}),"\n",(0,n.jsx)(o.p,{children:(0,n.jsx)(o.img,{alt:"roboflow_6",src:t(942).Z+"",width:"1901",height:"926"})}),"\n",(0,n.jsx)(o.p,{children:"Download your dataset"}),"\n",(0,n.jsx)(o.p,{children:(0,n.jsx)(o.img,{alt:"roboflow_7",src:t(7803).Z+"",width:"1919",height:"932"})}),"\n",(0,n.jsx)(o.pre,{children:(0,n.jsx)(o.code,{className:"language-python",children:"# Download gdown to install dataset from google driver, if you see 'install successfully' it means you install libs successfully, or when you see 'install error' it means you install libs unsuccessfully\ntry:\n    %pip install gdown -q\n    print('install successfully')\nexcept:\n    print('install error')\n"})}),"\n",(0,n.jsx)(o.pre,{children:(0,n.jsx)(o.code,{className:"language-python",children:"# Download your dataset, and you can also train your model on roboflow   \n!gdown https://drive.google.com/uc?id=1zZKnIVAcdNLUKg7IxaF-xLzE3Fvr3A05  && unzip roboflow.zip -d ~/datasets/ && rm roboflow.zip && mv ~/datasets/data.yaml ./data.yaml && cp -r ~/datasets/test/images ./\n"})}),"\n",(0,n.jsx)(o.h2,{id:"step-3-training-yolo11n",children:"Step 3: Training Yolo11n"}),"\n",(0,n.jsx)(o.p,{children:"YOLOv11 is the latest version in the YOLO (You Only Look Once) series developed by Ultralytics, following previous iterations like YOLOv5 and YOLOv8. It retains the key features of earlier versions, focusing on real-time object detection with improvements in speed, accuracy, and versatility across various tasks, such as object detection, segmentation, classification, and pose estimation."}),"\n",(0,n.jsx)(o.pre,{children:(0,n.jsx)(o.code,{className:"language-python",children:'from ultralytics import YOLO\n\n# Load a model\nmodel = YOLO("yolo11n.pt") # load a pretrained model (recommended for training)\n# Train model with 10 epochs\nresults = model.train(data="data.yaml", epochs=20, imgsz=640, batch=16)\n\n'})}),"\n",(0,n.jsx)(o.pre,{children:(0,n.jsx)(o.code,{className:"language-python",children:"%matplotlib inline\n\nimport cv2\nimport os\nimport matplotlib.pyplot as plt\nfrom ultralytics import YOLO\n\n# Define the image directory path\nimage_dir = './images/'\n\n# Get a list of all image files in the directory\nimage_files = [f for f in os.listdir(image_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\n\n# Loop through each image in the directory\nfor image_file in image_files:\n    image_path = os.path.join(image_dir, image_file)\n    image = cv2.imread(image_path)\n\n    # Perform prediction\n    results = model(image)\n\n    # Process the results and draw bounding boxes\n    for result in results:\n        # Extract bounding boxes\n        boxes = result.boxes\n        if boxes is not None:\n            for box in boxes:\n                x1, y1, x2, y2 = map(int, box.xyxy[0])  # Get bounding box coordinates\n                conf = box.conf[0]  # Confidence score\n                cls = int(box.cls[0])  # Class label index\n                label = f\"{model.names[cls]}: {conf:.2f}\"  # Create label text\n\n                # Draw the bounding box and label on the image\n                cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)  # Green box\n                cv2.putText(image, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)  # Green label\n\n    # Convert BGR image (from OpenCV) to RGB for displaying with matplotlib\n    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n    # Display the result image using matplotlib\n    plt.figure(figsize=(10, 6))\n    plt.imshow(image_rgb)\n    plt.axis('off')  # Hide axis\n    plt.title(f\"YOLO Prediction - {image_file}\")\n    plt.show()\n\n"})}),"\n",(0,n.jsx)(o.h2,{id:"step-4-export-to-onnx-format",children:"Step 4: Export to ONNX format"}),"\n",(0,n.jsx)(o.p,{children:"I will use Hailo DataFlow Compiler to convert model to hef format to inference on AI Kit, so I need to convert model to onnx format."}),"\n",(0,n.jsx)(o.pre,{children:(0,n.jsx)(o.code,{className:"language-python",children:'# Export Yolov11n model to onnx format, the path will be shown as below\n# For me the path is /home/jiahao/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/runs/detect/train/weights/best.onnx\n\nmodel.export(format="onnx", opset=10)\n'})})]})}function p(e={}){const{wrapper:o}={...(0,i.a)(),...e.components};return o?(0,n.jsx)(o,{...e,children:(0,n.jsx)(c,{...e})}):c(e)}},9387:(e,o,t)=>{t.d(o,{Z:()=>n});const n=t.p+"assets/images/roboflow_1-45aa25a0368806a07c0d7e7a685ef502.png"},8806:(e,o,t)=>{t.d(o,{Z:()=>n});const n=t.p+"assets/images/roboflow_2-263866ff450e0b3661128e1aa34d98da.png"},9918:(e,o,t)=>{t.d(o,{Z:()=>n});const n=t.p+"assets/images/roboflow_3-374527addc66fe1a962ceba321b9c7e2.png"},3837:(e,o,t)=>{t.d(o,{Z:()=>n});const n=t.p+"assets/images/roboflow_4-f48c1fabb11830f7672614813d531a2b.png"},5121:(e,o,t)=>{t.d(o,{Z:()=>n});const n=t.p+"assets/images/roboflow_5-1f62d44c8a4b61139db948a25c064004.png"},942:(e,o,t)=>{t.d(o,{Z:()=>n});const n=t.p+"assets/images/roboflow_6-6c9157d34540bb664e9c86a14542d671.png"},7803:(e,o,t)=>{t.d(o,{Z:()=>n});const n=t.p+"assets/images/roboflow_7-e3a1c82d6dc5a55a4d69e31a8dc2d4d8.png"},5260:(e,o,t)=>{t.d(o,{Z:()=>n});const n="data:image/png;base64,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"},1151:(e,o,t)=>{t.d(o,{Z:()=>s,a:()=>a});var n=t(7294);const i={},r=n.createContext(i);function a(e){const o=n.useContext(r);return n.useMemo((function(){return"function"==typeof e?e(o):{...o,...e}}),[o,e])}function s(e){let o;return o=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:a(e.components),n.createElement(r.Provider,{value:o},e.children)}}}]);