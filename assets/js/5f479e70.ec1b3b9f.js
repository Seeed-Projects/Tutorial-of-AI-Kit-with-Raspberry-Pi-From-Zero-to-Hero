"use strict";(self.webpackChunktutorial_of_ai_kit=self.webpackChunktutorial_of_ai_kit||[]).push([[873],{1962:(e,t,i)=>{i.r(t),i.d(t,{assets:()=>c,contentTitle:()=>s,default:()=>h,frontMatter:()=>r,metadata:()=>a,toc:()=>l});var n=i(5893),o=i(1151);const r={},s="Running AI Tasks with Hailo -With AI Kit",a={id:"Chapter_3-Computer_Vision_Projects_and_Practical_Applications/Run_Yolov8_on_Hailo_Environment",title:"Running AI Tasks with Hailo -With AI Kit",description:"Introduction",source:"@site/../articles/Chapter_3-Computer_Vision_Projects_and_Practical_Applications/Run_Yolov8_on_Hailo_Environment.md",sourceDirName:"Chapter_3-Computer_Vision_Projects_and_Practical_Applications",slug:"/Chapter_3-Computer_Vision_Projects_and_Practical_Applications/Run_Yolov8_on_Hailo_Environment",permalink:"/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/docs/Chapter_3-Computer_Vision_Projects_and_Practical_Applications/Run_Yolov8_on_Hailo_Environment",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Chapter 3 - Computer Vision Projects and Practical Applications",permalink:"/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/docs/Chapter_3-Computer_Vision_Projects_and_Practical_Applications/"},next:{title:"Chapter 4 - Large Language Model",permalink:"/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/docs/Chapter_4-Large_Language_Model/"}},c={},l=[{value:"Introduction",id:"introduction",level:2},{value:"Object Detection",id:"object-detection",level:2},{value:"Pose Estimation",id:"pose-estimation",level:2}];function d(e){const t={a:"a",code:"code",h1:"h1",h2:"h2",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.a)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(t.h1,{id:"running-ai-tasks-with-hailo--with-ai-kit",children:"Running AI Tasks with Hailo -With AI Kit"}),"\n",(0,n.jsx)(t.h2,{id:"introduction",children:"Introduction"}),"\n",(0,n.jsxs)(t.p,{children:["In the last chapter, we showed you how to set up the Raspberry Pi for various AI tasks. In this chapter, we will discuss how to perform ",(0,n.jsx)(t.strong,{children:"object detection and pose estimation"})," using the Hailo environment."]}),"\n",(0,n.jsxs)(t.p,{children:["If you haven't set up your device yet, please follow the ",(0,n.jsx)(t.a,{href:"https://seeed-projects.github.io/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/docs/Chapter_2-Configuring_the_RaspberryPi_Environment/Introduction_to_Hailo_in_Raspberry_Pi_Environment",children:"previous tutorial"})," first and then return to this one."]}),"\n",(0,n.jsxs)(t.p,{children:["The Hailo Model Zoo is a collection of pre-trained models using the ",(0,n.jsx)(t.strong,{children:"COCO dataset"})," for 80 classes. You can find various models trained by the Hailo team. In this tutorial, we will test ",(0,n.jsx)(t.strong,{children:"YOLOv8"}),", but you can explore other models, each with different architectures. The Hailo Model Zoo provides pre-trained models for high-performance deep learning applications."]}),"\n",(0,n.jsx)(t.p,{children:"Hailo provides different pre-trained models in ONNX/TF formats, as well as pre-compiled HEF (Hailo Executable Format) binary files to execute on Hailo devices."}),"\n",(0,n.jsxs)(t.p,{children:["Link to ",(0,n.jsx)(t.a,{href:"https://github.com/hailo-ai/hailo_model_zoo",children:"Model Zoo"})]}),"\n",(0,n.jsx)(t.p,{children:"In this tutorial, we will demonstrate object detection and pose estimation in the Hailo environment."}),"\n",(0,n.jsx)(t.h2,{id:"object-detection",children:"Object Detection"}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsx)(t.li,{children:"Clone the repository:"}),"\n"]}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-bash",children:"git clone https://github.com/Seeed-Projects/Benchmarking-YOLOv8-on-Raspberry-PI-reComputer-r1000-and-AIkit-Hailo-8L.git\n"})}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsx)(t.li,{children:"Navigate to directory"}),"\n"]}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-bash",children:"cd Benchmarking-YOLOv8-on-Raspberry-PI-reComputer-r1000-and-AIkit-Hailo-8L\n"})}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsx)(t.li,{children:"Run object detection:"}),"\n"]}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-bash",children:"bash ./run.sh object-detection-hailo\n"})}),"\n",(0,n.jsx)(t.p,{children:(0,n.jsx)(t.img,{alt:"object detection",src:i(7022).Z+"",width:"640",height:"360"})}),"\n",(0,n.jsxs)(t.p,{children:["We measured the inference speed of YOLOv8 for object detection with a ",(0,n.jsx)(t.strong,{children:"640\xd7640"})," input resolution using the AI kit. With Hailo acceleration, it reached ",(0,n.jsx)(t.strong,{children:"29.5"})," FPS."]}),"\n",(0,n.jsx)(t.h2,{id:"pose-estimation",children:"Pose Estimation"}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsx)(t.li,{children:"Clone the repository (if not already):"}),"\n"]}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-bash",children:"git clone https://github.com/Seeed-Projects/Benchmarking-YOLOv8-on-Raspberry-PI-reComputer-r1000-and-AIkit-Hailo-8L.git\n"})}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsx)(t.li,{children:"Navigate to directory"}),"\n"]}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-bash",children:"cd Benchmarking-YOLOv8-on-Raspberry-PI-reComputer-r1000-and-AIkit-Hailo-8L\n"})}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsx)(t.li,{children:"Run object detection:"}),"\n"]}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-bash",children:"bash run.sh pose-estimation-hailo\n"})}),"\n",(0,n.jsx)(t.p,{children:(0,n.jsx)(t.img,{alt:"pose estimation",src:i(6686).Z+"",width:"600",height:"338"})}),"\n",(0,n.jsxs)(t.p,{children:["The inference speed of YOLOv8 for pose estimation with a ",(0,n.jsx)(t.strong,{children:"640\xd7640"})," input resolution using Hailo acceleration and the AI kit reached ",(0,n.jsx)(t.strong,{children:"27"})," FPS."]})]})}function h(e={}){const{wrapper:t}={...(0,o.a)(),...e.components};return t?(0,n.jsx)(t,{...e,children:(0,n.jsx)(d,{...e})}):d(e)}},6686:(e,t,i)=>{i.d(t,{Z:()=>n});const n=i.p+"assets/images/YOLOv8-pose-estimation-with-AIkit-417b7ff25023f32b3ec3c81d35bbc171.gif"},7022:(e,t,i)=>{i.d(t,{Z:()=>n});const n=i.p+"assets/images/object_detection_with_AIkit-302d14410be99f8d6a3fc22811198955.gif"},1151:(e,t,i)=>{i.d(t,{Z:()=>a,a:()=>s});var n=i(7294);const o={},r=n.createContext(o);function s(e){const t=n.useContext(r);return n.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function a(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:s(e.components),n.createElement(r.Provider,{value:t},e.children)}}}]);