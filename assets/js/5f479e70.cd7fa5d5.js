"use strict";(self.webpackChunktutorial_of_ai_kit=self.webpackChunktutorial_of_ai_kit||[]).push([[873],{1962:(e,t,i)=>{i.r(t),i.d(t,{assets:()=>c,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>a,toc:()=>l});var n=i(5893),o=i(1151);const r={},s="Running AI Tasks with Hailo -With AI Kit (13TOPS)",a={id:"Chapter_3-Computer_Vision_Projects_and_Practical_Applications/Run_Yolov8_on_Hailo_Environment",title:"Running AI Tasks with Hailo -With AI Kit (13TOPS)",description:"Introduction",source:"@site/../articles/Chapter_3-Computer_Vision_Projects_and_Practical_Applications/Run_Yolov8_on_Hailo_Environment.md",sourceDirName:"Chapter_3-Computer_Vision_Projects_and_Practical_Applications",slug:"/Chapter_3-Computer_Vision_Projects_and_Practical_Applications/Run_Yolov8_on_Hailo_Environment",permalink:"/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/docs/Chapter_3-Computer_Vision_Projects_and_Practical_Applications/Run_Yolov8_on_Hailo_Environment",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Chapter 3 - Computer Vision Projects and Practical Applications",permalink:"/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/docs/Chapter_3-Computer_Vision_Projects_and_Practical_Applications/"},next:{title:"Chapter 4 - Large Language Model",permalink:"/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/docs/Chapter_4-Large_Language_Model/"}},c={},l=[{value:"Introduction",id:"introduction",level:2},{value:"Object Detection",id:"object-detection",level:3},{value:"Pose Estimation",id:"pose-estimation",level:3}];function h(e){const t={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.a)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(t.h1,{id:"running-ai-tasks-with-hailo--with-ai-kit-13tops",children:"Running AI Tasks with Hailo -With AI Kit (13TOPS)"}),"\n",(0,n.jsx)(t.h2,{id:"introduction",children:"Introduction"}),"\n",(0,n.jsx)(t.p,{children:"In the last chapter, we showed you how to set up the Raspberry Pi for various AI tasks. In this chapter, we will discuss how to perform object detection and pose estimation using the Hailo environment."}),"\n",(0,n.jsxs)(t.p,{children:["If you haven't set up your device yet, please follow the (previous tutorial)[",(0,n.jsx)(t.a,{href:"https://seeed-projects.github.io/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/docs/Chapter_2-Configuring_the_RaspberryPi_Environment/Introduction_to_Hailo_in_Raspberry_Pi_Environment",children:"https://seeed-projects.github.io/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/docs/Chapter_2-Configuring_the_RaspberryPi_Environment/Introduction_to_Hailo_in_Raspberry_Pi_Environment"}),"]"," first and then return to this one."]}),"\n",(0,n.jsxs)(t.p,{children:["The Hailo Model Zoo is a collection of pre-trained models using the ",(0,n.jsx)(t.strong,{children:"COCO dataset"})," for 80 classes. You can find various models trained by the Hailo team. In this tutorial, we will test ",(0,n.jsx)(t.strong,{children:"YOLOv8"}),", but you can explore other models, each with different architectures. The Hailo Model Zoo provides pre-trained models for high-performance deep learning applications."]}),"\n",(0,n.jsx)(t.p,{children:"Hailo provides different pre-trained models in ONNX/TF formats, as well as pre-compiled HEF (Hailo Executable Format) binary files to execute on Hailo devices."}),"\n",(0,n.jsxs)(t.p,{children:["Link to (Model Zoo)[",(0,n.jsx)(t.a,{href:"https://github.com/hailo-ai/hailo_model_zoo",children:"https://github.com/hailo-ai/hailo_model_zoo"}),"]"]}),"\n",(0,n.jsx)(t.p,{children:"In this tutorial, we will demonstrate object detection and pose estimation in the Hailo environment."}),"\n",(0,n.jsx)(t.h3,{id:"object-detection",children:"Object Detection"}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsx)(t.li,{children:"Clone the repository:"}),"\n"]}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-bash",children:"git clone https://github.com/Seeed-Projects/Benchmarking-YOLOv8-on-Raspberry-PI-reComputer-r1000-and-AIkit-Hailo-8L.git\n"})}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsx)(t.li,{children:"Navigate to directory"}),"\n"]}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-bash",children:"cd Benchmarking-YOLOv8-on-Raspberry-PI-reComputer-r1000-and-AIkit-Hailo-8L\n"})}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsx)(t.li,{children:"Run object detection:"}),"\n"]}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-bash",children:"bash ./run.sh object-detection-hailo\n"})}),"\n",(0,n.jsx)(t.p,{children:(0,n.jsx)(t.img,{alt:"object detection",src:i(7022).Z+"",width:"640",height:"360"})}),"\n",(0,n.jsxs)(t.p,{children:["We measured the inference speed of YOLOv8 for object detection with a ",(0,n.jsx)(t.strong,{children:"640\xd7640"})," input resolution using the AI kit. With Hailo acceleration, it reached ",(0,n.jsx)(t.strong,{children:"29.5"})," FPS."]}),"\n",(0,n.jsx)(t.h3,{id:"pose-estimation",children:"Pose Estimation"}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsx)(t.li,{children:"Clone the repository (if not already):"}),"\n"]}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-bash",children:"git clone https://github.com/Seeed-Projects/Benchmarking-YOLOv8-on-Raspberry-PI-reComputer-r1000-and-AIkit-Hailo-8L.git\n"})}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsx)(t.li,{children:"Navigate to directory"}),"\n"]}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-bash",children:"cd Benchmarking-YOLOv8-on-Raspberry-PI-reComputer-r1000-and-AIkit-Hailo-8L\n"})}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsx)(t.li,{children:"Run object detection:"}),"\n"]}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-bash",children:"bash run.sh pose-estimation-hailo\n"})}),"\n",(0,n.jsx)(t.p,{children:(0,n.jsx)(t.img,{alt:"pose estimation",src:i(6686).Z+"",width:"600",height:"338"})}),"\n",(0,n.jsxs)(t.p,{children:["The inference speed of YOLOv8 for pose estimation with a ",(0,n.jsx)(t.strong,{children:"640\xd7640"})," input resolution using Hailo acceleration and the AI kit reached ",(0,n.jsx)(t.strong,{children:"27"})," FPS."]})]})}function d(e={}){const{wrapper:t}={...(0,o.a)(),...e.components};return t?(0,n.jsx)(t,{...e,children:(0,n.jsx)(h,{...e})}):h(e)}},6686:(e,t,i)=>{i.d(t,{Z:()=>n});const n=i.p+"assets/images/YOLOv8-pose-estimation-with-AIkit-417b7ff25023f32b3ec3c81d35bbc171.gif"},7022:(e,t,i)=>{i.d(t,{Z:()=>n});const n=i.p+"assets/images/object_detection_with_AIkit-302d14410be99f8d6a3fc22811198955.gif"},1151:(e,t,i)=>{i.d(t,{Z:()=>a,a:()=>s});var n=i(7294);const o={},r=n.createContext(o);function s(e){const t=n.useContext(r);return n.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function a(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:s(e.components),n.createElement(r.Provider,{value:t},e.children)}}}]);