"use strict";(self.webpackChunktutorial_of_ai_kit=self.webpackChunktutorial_of_ai_kit||[]).push([[614],{5178:(e,i,t)=>{t.r(i),t.d(i,{assets:()=>a,contentTitle:()=>o,default:()=>j,frontMatter:()=>r,metadata:()=>s,toc:()=>c});var M=t(5893),n=t(1151);const r={sidebar_position:4},o="Introduction to Ultralytics in Raspberry Pi Environment",s={id:"Chapter 2 - Configuring the RaspberryPi Environment/Introduction_to_Ultralytics_in_Raspberry_Pi_Environment",title:"Introduction to Ultralytics in Raspberry Pi Environment",description:"Who is Ultralytics?",source:"@site/../articles/Chapter 2 - Configuring the RaspberryPi Environment/Introduction_to_Ultralytics_in_Raspberry_Pi_Environment.md",sourceDirName:"Chapter 2 - Configuring the RaspberryPi Environment",slug:"/Chapter 2 - Configuring the RaspberryPi Environment/Introduction_to_Ultralytics_in_Raspberry_Pi_Environment",permalink:"/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/docs/Chapter 2 - Configuring the RaspberryPi Environment/Introduction_to_Ultralytics_in_Raspberry_Pi_Environment",draft:!1,unlisted:!1,tags:[],version:"current",sidebarPosition:4,frontMatter:{sidebar_position:4},sidebar:"tutorialSidebar",previous:{title:"Introduction to OpenCV in Raspberry Pi Environment",permalink:"/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/docs/Chapter 2 - Configuring the RaspberryPi Environment/Introduction_to_OpenCV"},next:{title:"Introduction to Hailo in Raspberry Pi Environment",permalink:"/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/docs/Chapter 2 - Configuring the RaspberryPi Environment/Introduction_to_Hailo_in_Raspberry_Pi_Environment"}},a={},c=[{value:"Who is Ultralytics?",id:"who-is-ultralytics",level:2},{value:"Ultralytics on Raspberry Pi Environment",id:"ultralytics-on-raspberry-pi-environment",level:2},{value:"Step 1: Train and Export the Model",id:"step-1-train-and-export-the-model",level:3},{value:"Step 2: Set Up a Project Directory",id:"step-2-set-up-a-project-directory",level:3},{value:"Step 3: Create a Virtual Environment and Activate the virtual environment",id:"step-3-create-a-virtual-environment-and-activate-the-virtual-environment",level:3},{value:"Step 4: Install Required Libraries",id:"step-4-install-required-libraries",level:3},{value:"Step 5: Set Up the Code",id:"step-5-set-up-the-code",level:3},{value:"Step 6: Download the Necessary Files",id:"step-6-download-the-necessary-files",level:3},{value:"Step 7: Activate the virtual Environment",id:"step-7-activate-the-virtual-environment",level:3},{value:"Step 8: Run the YOLOv8 Model",id:"step-8-run-the-yolov8-model",level:3},{value:"Other Resources",id:"other-resources",level:2}];function l(e){const i={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,n.a)(),...e.components};return(0,M.jsxs)(M.Fragment,{children:[(0,M.jsx)(i.h1,{id:"introduction-to-ultralytics-in-raspberry-pi-environment",children:"Introduction to Ultralytics in Raspberry Pi Environment"}),"\n",(0,M.jsx)(i.h2,{id:"who-is-ultralytics",children:"Who is Ultralytics?"}),"\n",(0,M.jsx)(i.p,{children:(0,M.jsx)(i.img,{alt:"Ultralytics",src:t(5924).Z+"",width:"446",height:"93"})}),"\n",(0,M.jsxs)(i.p,{children:[(0,M.jsx)(i.a,{href:"https://www.ultralytics.com/",children:"Ultralytics"}),' is a company and open-source organization known for developing YOLOv5 and YOLOv8,YOLO11 popular deep learning models for real-time object detection. YOLO, short for "You Only Look Once," is a family of object detection models designed for high-speed, accurate detection in images and video. Ultralytics has made significant contributions to YOLO by optimizing its models for both performance and accessibility, making it popular in applications like surveillance, autonomous vehicles, robotics, and more.']}),"\n",(0,M.jsxs)(i.p,{children:["Ultralytics offers a diverse suite of models designed for specialized tasks such as ",(0,M.jsx)(i.strong,{children:"object detection, instance segmentation, image classification, pose estimation, and multi-object tracking."}),"\n",(0,M.jsx)(i.strong,{children:"YOLO11"})," Ultralytics\u2019 latest YOLO series delivers state-of-the-art (SOTA) performance across various tasks."]}),"\n",(0,M.jsx)(i.p,{children:"In this tutorial, we\u2019ll explore deploying YOLO11 on a Raspberry Pi. In the next tutorial, we\u2019ll dive into how to harness this remarkable architecture using the Hailo Accelerator."}),"\n",(0,M.jsx)(i.h2,{id:"ultralytics-on-raspberry-pi-environment",children:"Ultralytics on Raspberry Pi Environment"}),"\n",(0,M.jsx)(i.h3,{id:"step-1-train-and-export-the-model",children:"Step 1: Train and Export the Model"}),"\n",(0,M.jsxs)(i.p,{children:[(0,M.jsx)(i.strong,{children:"Ultralytics"})," provides the ",(0,M.jsx)(i.strong,{children:"COCO dataset"})," labels, which can be used to train the model. Initially, the model weights are provided in .pt format. To use the model on resource-constrained devices like the Raspberry Pi, we need to convert the weights into a quantized format.\nFor this, you can use the following Colab code to convert the model to a ",(0,M.jsx)(i.strong,{children:"TensorFlow Lite (TFLite)"})," format. In this case, we will train the ",(0,M.jsx)(i.strong,{children:"YOLO11n"})," model with an image size of 224x224, and then convert the trained model into the TFLite format for efficient deployment on the Raspberry Pi."]}),"\n",(0,M.jsx)("a",{target:"_blank",href:"https://colab.research.google.com/github/Seeed-Projects/Tutorial-of-AI-Kit-with-Raspberry-Pi-From-Zero-to-Hero/blob/main/notebook/Chapter2/yolov11n_to_convert_tflite.ipynb",children:(0,M.jsx)("img",{src:"https://colab.research.google.com/assets/colab-badge.svg",alt:"Open In Colab"})}),"\n",(0,M.jsx)(i.p,{children:"After running each cell in the Colab notebook, you'll generate two TFLite model files: one with 32-bit floating-point precision and the other with 16-bit precision. You can test either of these, but for this example, we will proceed with the 16-bit floating-point model. Download this file to continue."}),"\n",(0,M.jsx)(i.p,{children:(0,M.jsx)(i.img,{alt:"yolotraining",src:t(2249).Z+"",width:"1911",height:"631"})}),"\n",(0,M.jsx)(i.p,{children:"Let's Go to Raspberry Pi"}),"\n",(0,M.jsx)(i.h3,{id:"step-2-set-up-a-project-directory",children:"Step 2: Set Up a Project Directory"}),"\n",(0,M.jsx)(i.pre,{children:(0,M.jsx)(i.code,{className:"language-bash",children:"mkdir my_ultralytics\ncd my_ultralytics\n"})}),"\n",(0,M.jsx)(i.h3,{id:"step-3-create-a-virtual-environment-and-activate-the-virtual-environment",children:"Step 3: Create a Virtual Environment and Activate the virtual environment"}),"\n",(0,M.jsx)(i.pre,{children:(0,M.jsx)(i.code,{className:"language-bash",children:"python -m venv --system-site-packages env\nsource env/bin/activate\n"})}),"\n",(0,M.jsx)(i.h3,{id:"step-4-install-required-libraries",children:"Step 4: Install Required Libraries"}),"\n",(0,M.jsx)(i.pre,{children:(0,M.jsx)(i.code,{className:"language-bash",children:"pip install ultralytics tensorflow\nsudo reboot\n"})}),"\n",(0,M.jsx)(i.p,{children:(0,M.jsx)(i.img,{alt:"Install",src:t(9225).Z+"",width:"664",height:"351"})}),"\n",(0,M.jsx)(i.h3,{id:"step-5-set-up-the-code",children:"Step 5: Set Up the Code"}),"\n",(0,M.jsxs)(i.p,{children:[(0,M.jsx)(i.strong,{children:"Open Thonny Python IDE"})," and paste the following code snippet. Save the file on your desktop in a folder named ",(0,M.jsx)(i.code,{children:"Yolo_Files"})," with the filename ",(0,M.jsx)(i.code,{children:"test_yolo_coco.py"}),":"]}),"\n",(0,M.jsx)(i.pre,{children:(0,M.jsx)(i.code,{className:"language-bash",children:'import cv2\nimport time\nfrom ultralytics import YOLO\n\n# Load COCO class names\nwith open("coco.txt", "r") as f:\n    class_names = f.read().splitlines()\n\n# Load the YOLOv8 model (TFLite version)\nmodel = YOLO("best_float16.tflite")\n\n# Open the webcam\ncap = cv2.VideoCapture(0)\ncount = 0\n\n# Initialize variables for FPS calculation\nprev_time = 0\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    count += 1\n    if count % 3 != 0:\n        continue\n\n    current_time = time.time()\n\n    # Run YOLOv8 detection on the frame\n    results = model(frame, conf=0.7, imgsz=224)\n\n    for result in results:\n        boxes = result.boxes\n        for box in boxes:\n            x1, y1, x2, y2 = map(int, box.xyxy[0])\n            confidence = box.conf[0]\n            class_id = int(box.cls[0])\n            class_name = class_names[class_id]\n\n            # Draw the bounding box\n            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n\n            # Label the detection\n            label = f\'{class_name} {confidence:.2f}\'\n            cv2.putText(frame, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 2)\n\n    # Calculate and display FPS\n    fps = 1 / (current_time - prev_time)\n    prev_time = current_time\n    cv2.putText(frame, f\'FPS: {fps:.2f}\', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n\n    # Display the frame\n    cv2.imshow("Webcam", frame)\n    if cv2.waitKey(1) & 0xFF == ord("q"):\n        break\n\ncap.release()\ncv2.destroyAllWindows()\n\n'})}),"\n",(0,M.jsx)(i.h3,{id:"step-6-download-the-necessary-files",children:"Step 6: Download the Necessary Files"}),"\n",(0,M.jsx)(i.p,{children:"Save the following files in the Yolo_Files folder"}),"\n",(0,M.jsxs)(i.ul,{children:["\n",(0,M.jsxs)(i.li,{children:[(0,M.jsx)(i.strong,{children:"best_float16.tflite"}),": ",(0,M.jsx)(i.a,{target:"_blank",href:t(2587).Z+"",children:"The TFLite mode"})," file."]}),"\n",(0,M.jsxs)(i.li,{children:[(0,M.jsx)(i.strong,{children:"coco.txt"}),": A text file containing the ",(0,M.jsx)(i.a,{target:"_blank",href:t(8270).Z+"",children:"COCO dataset labels"}),"."]}),"\n"]}),"\n",(0,M.jsx)(i.p,{children:(0,M.jsx)(i.img,{alt:"Files",src:t(6293).Z+"",width:"1022",height:"300"})}),"\n",(0,M.jsx)(i.h3,{id:"step-7-activate-the-virtual-environment",children:"Step 7: Activate the virtual Environment"}),"\n",(0,M.jsx)(i.pre,{children:(0,M.jsx)(i.code,{className:"language-bash",children:"cd my_ultralytics\nsource env/bin/activate\n"})}),"\n",(0,M.jsx)(i.h3,{id:"step-8-run-the-yolov8-model",children:"Step 8: Run the YOLOv8 Model"}),"\n",(0,M.jsx)(i.p,{children:"Navigate to the Yolo_Files folder and Run the Python script"}),"\n",(0,M.jsx)(i.pre,{children:(0,M.jsx)(i.code,{className:"language-bash",children:"cd /home/pi/Desktop/Yolo_Files\npython test_yolo_coco.py\n"})}),"\n",(0,M.jsx)(i.p,{children:(0,M.jsx)(i.img,{alt:"Files",src:t(3714).Z+"",width:"1012",height:"763"})}),"\n",(0,M.jsxs)(i.p,{children:["Press ",(0,M.jsx)(i.code,{children:"q"})," to quit the application while it\u2019s running."]}),"\n",(0,M.jsxs)(i.p,{children:["You may notice a slight delay in the FPS (frames per second) while running this model, as it relies on the Raspberry Pi\u2019s CPU for inference. CPU-only mode can limit real-time performance, making it challenging for tasks that require quick responsiveness. This is where the ",(0,M.jsx)(i.strong,{children:"Hailo accelerator"})," (the AI Kit for Raspberry Pi) becomes essential, offering optimized processing that enhances real-time performance for applications like object detection, tracking, and other AI-driven tasks."]}),"\n",(0,M.jsx)(i.h2,{id:"other-resources",children:"Other Resources"}),"\n",(0,M.jsxs)(i.p,{children:[(0,M.jsx)(i.a,{href:"https://docs.ultralytics.com/guides/raspberry-pi/",children:"Quick Start Guide: Raspberry Pi with Ultralytics YOLO11"}),"\n",(0,M.jsx)(i.a,{href:"https://docs.ultralytics.com/modes/export/",children:"Model Export with Ultralytics YOLO"}),"\n",(0,M.jsx)(i.a,{href:"https://docs.ultralytics.com/integrations/tflite/#deployment-options-in-tflite",children:"A Guide on YOLO11 Model Export to TFLite for Deployment"})]})]})}function j(e={}){const{wrapper:i}={...(0,n.a)(),...e.components};return i?(0,M.jsx)(i,{...e,children:(0,M.jsx)(l,{...e})}):l(e)}},2587:(e,i,t)=>{t.d(i,{Z:()=>M});const M=t.p+"assets/files/best_float16-c9048c2377ce94dde4c1db6c96277089.tflite"},8270:(e,i,t)=>{t.d(i,{Z:()=>M});const M=t.p+"assets/files/coco-3515403c7b04ee4ed9f3925ec790b66c.txt"},6293:(e,i,t)=>{t.d(i,{Z:()=>M});const M=t.p+"assets/images/files_yolo-d85e4fc3a57061bf3db97ced603f7fae.PNG"},9225:(e,i,t)=>{t.d(i,{Z:()=>M});const M=t.p+"assets/images/install_ultra_tf-bd7d118f90e320d64650344f3dc79278.PNG"},3714:(e,i,t)=>{t.d(i,{Z:()=>M});const M=t.p+"assets/images/results-b7239e805e8aa18ccb3e2011f4b7e0d7.PNG"},5924:(e,i,t)=>{t.d(i,{Z:()=>M});const M="data:image/svg+xml;base64,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"},2249:(e,i,t)=>{t.d(i,{Z:()=>M});const M=t.p+"assets/images/yolotraining-31647acaa48a09de78c5c6604a63fc53.PNG"},1151:(e,i,t)=>{t.d(i,{Z:()=>s,a:()=>o});var M=t(7294);const n={},r=M.createContext(n);function o(e){const i=M.useContext(r);return M.useMemo((function(){return"function"==typeof e?e(i):{...i,...e}}),[i,e])}function s(e){let i;return i=e.disableParentContext?"function"==typeof e.components?e.components(n):e.components||n:o(e.components),M.createElement(r.Provider,{value:i},e.children)}}}]);